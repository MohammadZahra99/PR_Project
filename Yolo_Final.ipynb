{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1ab369-e19f-4110-97ac-0cab04bae28f",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c32841-5762-4c04-92b0-7c393e8d8a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run this if ultralytics not already installed on your machine\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0c55e-e692-4e20-8c95-f0a9aaaad782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this for prediction, be sure to change img variable to path to your image\n",
    "from ultralytics import YOLO\n",
    "model = YOLO('model.pt')\n",
    "img = \"path\\to\\img\"\n",
    "model.predict(img,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a9187-a796-49b4-8036-93272d592bc8",
   "metadata": {},
   "source": [
    "## Dataset Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0eecd8-18e7-434f-a90b-1f07c41d7902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=19.30s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of exclusive images found: 68091\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "def fetch_exclusive_class_images(annotation_file, desired_classes):\n",
    "    \"\"\"\n",
    "    This function loads the COCO dataset and returns a list with only the classes defined in the desired_classes variable\n",
    "    -------\n",
    "    Parameters:\n",
    "        annotation_file(str): Path to COCO dataset annotation file\n",
    "        desired_classes(list): List of classes you want the function to search for\n",
    "    Returns:\n",
    "        unique_img_ids(list): List of unique images that match the desired classes\n",
    "    \"\"\"\n",
    "    # Initialize COCO API\n",
    "    coco = COCO(annotation_file)\n",
    "\n",
    "    # Get category IDs for desired classes\n",
    "    cat_ids = coco.getCatIds(catNms=desired_classes)\n",
    "\n",
    "    # Unique Images to be returned by function\n",
    "    unique_img_ids = set()\n",
    "\n",
    "    for cat_id in cat_ids:\n",
    "        # Get all image IDs containing the current class\n",
    "        img_ids = coco.getImgIds(catIds=[cat_id])\n",
    "\n",
    "        for img_id in img_ids:\n",
    "            # Skip if we have already processed this image\n",
    "            if img_id in unique_img_ids:\n",
    "                continue\n",
    "\n",
    "            # Get all annotations for the image\n",
    "            ann_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "            annotations = coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Check if the image contains only objects from the desired classes\n",
    "            if all(ann['category_id'] in cat_ids for ann in annotations):\n",
    "                unique_img_ids.add(img_id)\n",
    "    \n",
    "    return list(unique_img_ids)\n",
    "\n",
    "# Path to the COCO annotation file\n",
    "annotation_file = r'C:\\Users\\Moham\\datasets\\coco\\annotations\\instances_train2017.json'\n",
    "\n",
    "# Define desired classes\n",
    "desired_classes = ['bicycle','person', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', \n",
    "                   'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', \n",
    "                   'horse', 'sheep', 'cow', 'backpack', 'umbrella', 'handbag',  'suitcase', 'frisbee', 'sports ball',\n",
    "                   'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
    "                   'chair', 'couch', 'potted plant', 'dining table', 'toilet' ,'tv' ,'laptop', 'mouse', 'keyboard',\n",
    "                   'cell phone', 'sink', 'book', 'clock', 'vase' ]   \n",
    "\n",
    "# Test function before using in later instances\n",
    "exclusive_images = fetch_exclusive_class_images(annotation_file, desired_classes)\n",
    "\n",
    "print(f\"Number of exclusive images found: {len(exclusive_images)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7374ec5-8919-400c-992e-844d9a9022f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=19.98s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=17.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset split and copied successfully.\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(exclusive_images, train_size, test_size, val_size, source_dir, dest_dir, annotation_file):\n",
    "    \"\"\"\n",
    "    This function takes the list of exclusive images, splits them according to a set number of train:test:val and saves them to file\n",
    "    Parameters:\n",
    "        exclusive_images (list): List of images to be split\n",
    "        train_size (int): number of train images\n",
    "        test_size (int): number of test images\n",
    "        val_size (int): number of validation images\n",
    "        source_dir (str): Path to COCO images we want to split from \n",
    "        dest_dir (str): Path to directory we want the split images saved to\n",
    "        annotation_file (str): Path to COCO annotation file\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize COCO API \n",
    "    coco = COCO(annotation_file)\n",
    "\n",
    "    # Shuffle the exclusive images list\n",
    "    random.shuffle(exclusive_images)\n",
    "\n",
    "    # Split the dataset\n",
    "    train_images = exclusive_images[:train_size]\n",
    "    test_images = exclusive_images[train_size:train_size + test_size]\n",
    "    val_images = exclusive_images[train_size + test_size:train_size + test_size + val_size]\n",
    "\n",
    "    # Function to copy images to the respective folders\n",
    "    def copy_images(image_ids, split_type):\n",
    "        split_dir = os.path.join(dest_dir, split_type, 'images')\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        for img_id in image_ids:\n",
    "            img_info = coco.loadImgs(img_id)[0]\n",
    "            source_path = os.path.join(source_dir, img_info['file_name'])\n",
    "            dest_path = os.path.join(split_dir, img_info['file_name'])\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "\n",
    "    # Copy images to their respective directories\n",
    "    copy_images(train_images, 'train')\n",
    "    copy_images(test_images, 'test')\n",
    "    copy_images(val_images, 'val')\n",
    "\n",
    "# Source and destination directories\n",
    "source_dir = r'datasets\\coco\\images\\train2017'  \n",
    "dest_dir = r'coco_custom'    \n",
    "\n",
    "# Path to COCO annotation file\n",
    "annotation_file = r'datasets\\coco\\annotations\\instances_train2017.json' \n",
    "\n",
    "# Run this if previous function hasn't been run before\n",
    "#exclusive_images = fetch_exclusive_class_images(annotation_file, desired_classes)\n",
    "\n",
    "# Function call\n",
    "split_dataset(exclusive_images, 8000, 1500, 500, source_dir, dest_dir, annotation_file)\n",
    "\n",
    "print(\"Dataset split and copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91dfe416-9457-4d8d-b329-4a40ea865194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels copied successfully to train, test, and val folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_labels_to_splits(base_img_dir, source_label_dir, split_types):\n",
    "    \"\"\"\n",
    "    This function copies the labels from the original COCO dataset for the respective split images\n",
    "    Parameters: \n",
    "        base_img_dir (str): Path of copied images \n",
    "        source_label_dir (str): Path of labels from original COCO dataset\n",
    "        split_types (list): List of splits, most probably ['train', 'test', 'val']\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    for split in split_types:\n",
    "        img_dir = os.path.join(base_img_dir, split, 'images')\n",
    "        label_dir = os.path.join(base_img_dir, split, 'labels')\n",
    "        os.makedirs(label_dir, exist_ok=True)  # Create label directory if it doesn't exist\n",
    "\n",
    "        for img_file in os.listdir(img_dir):\n",
    "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "            source_label_path = os.path.join(source_label_dir, label_file)\n",
    "            dest_label_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "            if os.path.exists(source_label_path):\n",
    "                shutil.copy2(source_label_path, dest_label_path)\n",
    "\n",
    "# Base directory for split images and the source directory for original COCO labels\n",
    "base_img_dir = r'coco_custom'  \n",
    "source_label_dir = r'datasets\\coco\\labels\\train2017'  \n",
    "\n",
    "# Function call\n",
    "copy_labels_to_splits(base_img_dir, source_label_dir, ['train', 'test', 'val'])\n",
    "\n",
    "print(\"Labels copied successfully to train, test, and val folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314eb37-7d65-4261-abcc-fc53121cd6ca",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8024554-dabb-455c-9889-abf659e28227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.230 🚀 Python-3.10.9 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce RTX 2060 SUPER, 8192MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Moham\\OneDrive - University Of Jordan\\Study\\1st Semester 2023\\PR\\coco_custom\\val\\labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:05<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       3364      0.718      0.585      0.649       0.48\n",
      "                person        500       1216      0.787      0.653      0.746      0.511\n",
      "               bicycle        500         65      0.798      0.369      0.508      0.315\n",
      "                   car        500        231      0.699       0.55      0.648       0.41\n",
      "            motorcycle        500         48      0.761      0.688      0.752      0.462\n",
      "              airplane        500         33      0.689      0.727       0.73      0.601\n",
      "                   bus        500         31      0.811      0.774       0.82      0.728\n",
      "                 train        500         16      0.695      0.855      0.884      0.717\n",
      "                 truck        500         72      0.616      0.445      0.549      0.416\n",
      "                  boat        500         69      0.813      0.441      0.538      0.285\n",
      "         traffic light        500        104      0.722      0.399      0.523      0.301\n",
      "          fire hydrant        500          7      0.799      0.714      0.811      0.647\n",
      "             stop sign        500         13      0.859      0.692      0.759      0.712\n",
      "         parking meter        500          9      0.383      0.444       0.53      0.335\n",
      "                 bench        500         62       0.62      0.316       0.34       0.24\n",
      "                  bird        500         82      0.764      0.315      0.467       0.26\n",
      "                   cat        500         21      0.908      0.939      0.958      0.702\n",
      "                   dog        500         26       0.91      0.777      0.888      0.756\n",
      "                 horse        500         30      0.735        0.8      0.824       0.69\n",
      "                 sheep        500         86      0.761      0.814      0.867      0.632\n",
      "                   cow        500         74      0.735      0.878       0.87      0.632\n",
      "              backpack        500         46      0.516       0.14      0.221      0.141\n",
      "              umbrella        500         86      0.632      0.442      0.437      0.276\n",
      "               handbag        500         66      0.468      0.147      0.186      0.107\n",
      "              suitcase        500         32      0.666      0.656        0.7      0.502\n",
      "               frisbee        500         16       0.64      0.562        0.5      0.381\n",
      "           sports ball        500         32      0.921      0.531      0.606      0.406\n",
      "                  kite        500         74      0.749      0.635      0.672      0.439\n",
      "          baseball bat        500         10      0.719        0.7      0.732      0.451\n",
      "        baseball glove        500         21      0.681      0.611      0.698      0.461\n",
      "            skateboard        500         33      0.749      0.727      0.736        0.5\n",
      "             surfboard        500         41      0.738      0.585       0.63      0.392\n",
      "         tennis racket        500         33      0.696      0.834      0.852      0.594\n",
      "                bottle        500         17      0.698      0.588      0.615      0.464\n",
      "                 chair        500        155        0.6      0.342      0.422       0.27\n",
      "                 couch        500         16      0.622      0.625      0.622       0.54\n",
      "          potted plant        500         44      0.624      0.477      0.592      0.378\n",
      "          dining table        500         27      0.637      0.185      0.345      0.266\n",
      "                toilet        500         28      0.747      0.821      0.892      0.781\n",
      "                    tv        500         45      0.798      0.622      0.791      0.632\n",
      "                laptop        500         25      0.766       0.68       0.72      0.599\n",
      "                 mouse        500          9      0.826      0.667      0.714      0.586\n",
      "              keyboard        500         14      0.672        0.5        0.6      0.523\n",
      "            cell phone        500         43      0.896      0.581      0.661      0.528\n",
      "                  sink        500         13      0.844      0.833      0.861       0.73\n",
      "                  book        500         57      0.408      0.105      0.192      0.094\n",
      "                 clock        500         35      0.807      0.719      0.745        0.6\n",
      "                  vase        500         51      0.777      0.608      0.727       0.56\n",
      "Speed: 0.2ms preprocess, 2.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val21\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n') #Base YOLOv8n model\n",
    "metrics = model.val(data='coco_custom.yaml', plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3f5477-5098-4ed7-9f4f-40186d19ed5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.230 🚀 Python-3.10.9 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce RTX 2060 SUPER, 8192MiB)\n",
      "Model summary (fused): 218 layers, 25886080 parameters, 0 gradients, 78.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Moham\\OneDrive - University Of Jordan\\Study\\1st Semester 2023\\PR\\coco_custom\\val\\labels.cache... 500 images, 0 backgrounds, 0 corrupt: 100%|██████████| 500/500 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:22<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        500       3364      0.702      0.633      0.677        0.5\n",
      "                person        500       1216      0.765      0.734      0.796      0.571\n",
      "               bicycle        500         65      0.841      0.569      0.691      0.423\n",
      "                   car        500        231      0.702      0.649      0.725        0.5\n",
      "            motorcycle        500         48      0.697      0.771      0.792      0.542\n",
      "              airplane        500         33      0.812      0.758      0.814       0.67\n",
      "                   bus        500         31      0.682      0.806      0.865      0.741\n",
      "                 train        500         16      0.716      0.787      0.817      0.673\n",
      "                 truck        500         72      0.601      0.486      0.589      0.446\n",
      "                  boat        500         69      0.817      0.522      0.623      0.363\n",
      "         traffic light        500        104      0.707       0.51      0.626      0.377\n",
      "          fire hydrant        500          7      0.652      0.857      0.797      0.659\n",
      "             stop sign        500         13          1      0.674      0.781      0.716\n",
      "         parking meter        500          9      0.439      0.556      0.511      0.372\n",
      "                 bench        500         62      0.577      0.323      0.361      0.247\n",
      "                  bird        500         82      0.782      0.402      0.504      0.312\n",
      "                   cat        500         21      0.906      0.857      0.958       0.65\n",
      "                   dog        500         26      0.686      0.808      0.819      0.664\n",
      "                 horse        500         30        0.7      0.779      0.787      0.646\n",
      "                 sheep        500         86      0.666      0.849      0.851      0.665\n",
      "                   cow        500         74      0.703      0.851      0.868      0.643\n",
      "              backpack        500         46      0.423      0.319      0.246       0.14\n",
      "              umbrella        500         86      0.567       0.61      0.515      0.314\n",
      "               handbag        500         66      0.534      0.318      0.327      0.185\n",
      "              suitcase        500         32      0.653      0.469      0.566      0.417\n",
      "               frisbee        500         16      0.612       0.75      0.594      0.474\n",
      "           sports ball        500         32      0.868      0.719       0.78      0.549\n",
      "                  kite        500         74      0.787      0.716      0.758      0.517\n",
      "          baseball bat        500         10      0.773        0.9      0.922      0.582\n",
      "        baseball glove        500         21      0.739       0.81      0.863      0.593\n",
      "            skateboard        500         33      0.745      0.758      0.793      0.589\n",
      "             surfboard        500         41      0.814      0.634      0.669      0.464\n",
      "         tennis racket        500         33      0.913      0.954      0.971       0.68\n",
      "                bottle        500         17      0.563      0.588      0.596      0.407\n",
      "                 chair        500        155      0.491       0.31      0.318      0.199\n",
      "                 couch        500         16      0.474      0.438      0.495      0.431\n",
      "          potted plant        500         44      0.815        0.5      0.672      0.374\n",
      "          dining table        500         27      0.432      0.226      0.307      0.208\n",
      "                toilet        500         28      0.694      0.786      0.745      0.688\n",
      "                    tv        500         45      0.935      0.637      0.794      0.635\n",
      "                laptop        500         25      0.853       0.68      0.787      0.612\n",
      "                 mouse        500          9      0.842      0.778      0.839       0.69\n",
      "              keyboard        500         14      0.791        0.5      0.614      0.501\n",
      "            cell phone        500         43      0.718      0.533       0.63       0.46\n",
      "                  sink        500         13      0.665      0.692      0.688      0.602\n",
      "                  book        500         57      0.293      0.158      0.152     0.0851\n",
      "                 clock        500         35       0.76      0.723      0.791      0.626\n",
      "                  vase        500         51      0.797      0.686      0.815      0.596\n",
      "Speed: 0.4ms preprocess, 33.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val34\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('model.pt') #Our custom model\n",
    "metrics = model.val(data='coco_custom.yaml', plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191591b-6a39-4642-b070-afba3daaa1d7",
   "metadata": {},
   "source": [
    "## Model Prediction on Webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6375674-133f-488a-987e-1f57346dc4f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Note: in some cases, after pressing q to end the feed and stop the program, memory leak might happen and you would have to restart the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed5403-e9b9-4dd2-8a53-80ceb17eb091",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8e409-0179-40eb-a791-3f6c6209794a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1360)\n",
    "cap.set(4, 720)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"model.pt\")\n",
    "\n",
    "# object classes\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ] \n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # class name\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # object details\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2069f-6617-4394-920c-b07005aed958",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model prediction on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a027b22-e2a6-4a04-bc1a-d6faa06bb291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "VIDEO_PATH = \"path\\to\\video\"\n",
    "\n",
    "model = YOLO('model.pt')\n",
    "video_info = sv.VideoInfo.from_video_path(VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856034f-f3df-4994-8f5b-6585de0aacbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to run prediction on every frame of video and save video \n",
    "def process_frame(frame: np.ndarray, _) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Processes a single video frame for object detection.\n",
    "    This function applies a pre-trained model to detect objects in an image frame and applies annotation with bounding boxes and class labels\n",
    "    Parameters:\n",
    "    frame (np.ndarray): A single frame of the video as a NumPy array.\n",
    "    _ (ignored): A placeholder for an optional second argument that is not used.\n",
    "    Returns:\n",
    "    np.ndarray: The processed frame with object detections annotated.\n",
    "    The function uses the 'model' variable which should be a pre-loaded model for object \n",
    "    detection.\n",
    "    \"\"\"\n",
    "    results = model(frame, imgsz=1280)[0]\n",
    "    \n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "    labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, _, confidence, class_id, _ in detections]\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "sv.process_video(source_path=VIDEO_PATH, target_path=f\"result.mp4\", callback=process_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
